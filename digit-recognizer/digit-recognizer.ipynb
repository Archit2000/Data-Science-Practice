{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"digit-recognizer\\train.csv\")\n",
    "test = pd.read_csv(r\"digit-recognizer\\test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_train = train[\"label\"]\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "sns.countplot(data = train,x='label')\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null values handeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any().describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization, Reshape, Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "test = test / 255.0\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d1582ba560>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\archi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\legacy\\rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 - 93s - loss: 0.2028 - accuracy: 0.9391 - val_loss: 0.0525 - val_accuracy: 0.9843 - lr: 0.0010 - 93s/epoch - 211ms/step\n",
      "Epoch 2/50\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 - 86s - loss: 0.1125 - accuracy: 0.9663 - val_loss: 0.0335 - val_accuracy: 0.9881 - lr: 0.0010 - 86s/epoch - 195ms/step\n",
      "Epoch 3/50\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 - 86s - loss: 0.0895 - accuracy: 0.9741 - val_loss: 0.0417 - val_accuracy: 0.9898 - lr: 0.0010 - 86s/epoch - 196ms/step\n",
      "Epoch 4/50\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 - 86s - loss: 0.0797 - accuracy: 0.9769 - val_loss: 0.0288 - val_accuracy: 0.9912 - lr: 0.0010 - 86s/epoch - 195ms/step\n",
      "Epoch 5/50\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 - 87s - loss: 0.0711 - accuracy: 0.9789 - val_loss: 0.0345 - val_accuracy: 0.9898 - lr: 0.0010 - 87s/epoch - 197ms/step\n",
      "Epoch 6/50\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 - 85s - loss: 0.0666 - accuracy: 0.9803 - val_loss: 0.0215 - val_accuracy: 0.9924 - lr: 0.0010 - 85s/epoch - 194ms/step\n",
      "Epoch 7/50\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 - 93s - loss: 0.0643 - accuracy: 0.9814 - val_loss: 0.0241 - val_accuracy: 0.9914 - lr: 0.0010 - 93s/epoch - 212ms/step\n",
      "Epoch 8/50\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 - 87s - loss: 0.0613 - accuracy: 0.9828 - val_loss: 0.0336 - val_accuracy: 0.9917 - lr: 0.0010 - 87s/epoch - 199ms/step\n",
      "Epoch 9/50\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 - 85s - loss: 0.0605 - accuracy: 0.9826 - val_loss: 0.0323 - val_accuracy: 0.9910 - lr: 0.0010 - 85s/epoch - 194ms/step\n",
      "Epoch 10/50\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 - 85s - loss: 0.0607 - accuracy: 0.9823 - val_loss: 0.0270 - val_accuracy: 0.9919 - lr: 0.0010 - 85s/epoch - 194ms/step\n",
      "Epoch 11/50\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 - 93s - loss: 0.0616 - accuracy: 0.9834 - val_loss: 0.0245 - val_accuracy: 0.9938 - lr: 0.0010 - 93s/epoch - 211ms/step\n",
      "Epoch 12/50\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 - 89s - loss: 0.0613 - accuracy: 0.9824 - val_loss: 0.0257 - val_accuracy: 0.9929 - lr: 0.0010 - 89s/epoch - 204ms/step\n",
      "Epoch 13/50\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 - 87s - loss: 0.0600 - accuracy: 0.9838 - val_loss: 0.0297 - val_accuracy: 0.9929 - lr: 0.0010 - 87s/epoch - 197ms/step\n",
      "Epoch 14/50\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 - 92s - loss: 0.0604 - accuracy: 0.9837 - val_loss: 0.0250 - val_accuracy: 0.9938 - lr: 0.0010 - 92s/epoch - 209ms/step\n",
      "Epoch 15/50\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 - 90s - loss: 0.0624 - accuracy: 0.9837 - val_loss: 0.0223 - val_accuracy: 0.9924 - lr: 0.0010 - 90s/epoch - 206ms/step\n",
      "Epoch 16/50\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 - 89s - loss: 0.0627 - accuracy: 0.9839 - val_loss: 0.0259 - val_accuracy: 0.9933 - lr: 0.0010 - 89s/epoch - 203ms/step\n",
      "Epoch 17/50\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 - 91s - loss: 0.0667 - accuracy: 0.9823 - val_loss: 0.0383 - val_accuracy: 0.9902 - lr: 0.0010 - 91s/epoch - 208ms/step\n",
      "Epoch 18/50\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "439/439 - 90s - loss: 0.0712 - accuracy: 0.9823 - val_loss: 0.0331 - val_accuracy: 0.9919 - lr: 0.0010 - 90s/epoch - 205ms/step\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlearning_rate_reduction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\archi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\archi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1676\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1674\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m   1675\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m-> 1676\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1677\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m             epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m             _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m         ):\n\u001b[0;32m   1684\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32mc:\\Users\\archi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py:1375\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1375\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1376\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1377\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[0;32m   1380\u001b[0m )\n\u001b[0;32m   1382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32mc:\\Users\\archi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:647\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    646\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 647\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    648\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    649\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\archi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:774\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \n\u001b[0;32m    767\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;124;03m  The value of the variable.\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 774\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[1;32mc:\\Users\\archi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:753\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    751\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 753\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    756\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    757\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    758\u001b[0m   tape\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[0;32m    759\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[0;32m    760\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    761\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32mc:\\Users\\archi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:743\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m    742\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m--> 743\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    745\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\archi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:580\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    579\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 580\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    583\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_val,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = (Y_pred_classes - Y_true != 0)\n",
    "\n",
    "Y_pred_classes_errors = Y_pred_classes[errors]\n",
    "Y_pred_errors = Y_pred[errors]\n",
    "Y_true_errors = Y_true[errors]\n",
    "X_val_errors = X_val[errors]\n",
    "\n",
    "def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n",
    "    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n",
    "            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n",
    "            n += 1\n",
    "\n",
    "# Probabilities of the wrong predicted numbers\n",
    "Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n",
    "\n",
    "# Predicted probabilities of the true values in the error set\n",
    "true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
    "\n",
    "# Difference between the probability of the predicted label and the true label\n",
    "delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
    "\n",
    "# Sorted list of the delta prob errors\n",
    "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
    "\n",
    "# Top 6 errors \n",
    "most_important_errors = sorted_dela_errors[-6:]\n",
    "\n",
    "# Show the top 6 errors\n",
    "display_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")\n",
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
